<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>FaceID Debug Demo</title>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        body { margin: 0; background: #121212; color: white; font-family: sans-serif; display: flex; flex-direction: column; align-items: center; }
        .container { position: relative; }
        canvas { position: absolute; top: 0; left: 0; }
        video { border-radius: 8px; border: 2px solid #444; }
        #status { margin: 20px; padding: 10px; border-radius: 5px; background: #222; }
    </style>
</head>
<body>

    <h2>Biometric Face Scan Demo</h2>
    <div id="status">Status: Initializing...</div>

    <div class="container">
        <video id="video" width="640" height="480" autoplay muted></video>
    </div>

    <script>
        const video = document.getElementById('video');
        const status = document.getElementById('status');

        async function setup() {
            try {
                status.innerText = "Status: Loading AI Models...";
                // Using a reliable mirror for models
                const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models';
                
                await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
                await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
                
                status.innerText = "Status: Models Loaded. Requesting Camera...";
                
                const stream = await navigator.mediaDevices.getUserMedia({ video: {} });
                video.srcObject = stream;
            } catch (err) {
                status.innerText = "Error: " + err.message;
                console.error(err);
            }
        }

        video.addEventListener('play', () => {
            const canvas = faceapi.createCanvasFromMedia(video);
            document.querySelector('.container').append(canvas);
            const displaySize = { width: video.width, height: video.height };
            faceapi.matchDimensions(canvas, displaySize);

            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();
                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                
                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                faceapi.draw.drawDetections(canvas, resizedDetections);
                faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);

                if (detections.length > 0) {
                    status.style.color = "#0f0";
                    status.innerText = "Status: Identity Verified âœ…";
                } else {
                    status.style.color = "white";
                    status.innerText = "Status: Scanning...";
                }
            }, 100);
        });

        setup();
    </script>
</body>
</html>
